{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####This notebook analyzes the \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import os, sys,z5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob \n",
    "from skimage.measure import regionprops\n",
    "from skimage.io import imread, imsave\n",
    "from os.path import abspath, dirname\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('default')\n",
    "from scipy import stats, spatial\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import binarize,StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.inspection import permutation_importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lha_neuron=pd.read_csv('/Users/wangy6/Desktop/FISH/LHA_FISH_gene.csv',sep=',', index_col=0)\n",
    "ex_m=pd.read_csv('/Users/wangy6/Desktop/LHA_figures/Slc17a6_metadata_tsne_v6.csv',sep=',', index_col=0)\n",
    "inh_m=pd.read_csv('/Users/wangy6/Desktop/LHA_figures/Slc32a1_metadata_tsne_v6.csv',sep=',', index_col=0)\n",
    "lha_neuron=lha_neuron.T\n",
    "ex_m.x='Ex_' + ex_m.x.astype(str)\n",
    "inh_m.x='Inh_' + inh_m.x.astype(str)\n",
    "lha_neuron=lha_neuron.where(lha_neuron>=0, 0)\n",
    "\n",
    "\n",
    "cluster=pd.concat([ex_m,inh_m],axis=0)\n",
    "\n",
    "c=['Ex_1', 'Ex_2', 'Ex_3', 'Ex_4',\n",
    "       'Ex_5', 'Ex_6', 'Ex_7', 'Ex_8', 'Ex_9', 'Ex_10', 'Ex_11', 'Ex_12', 'Ex_13', 'Ex_14', \n",
    "       'Ex_15', 'Ex_16', 'Ex_17', 'Ex_18', 'Ex_19', 'Ex_20',\n",
    "       'Ex_21', 'Ex_22', 'Ex_23', 'Ex_24', 'Ex_25','Inh_1', 'Inh_2','Inh_3', 'Inh_4', 'Inh_5', 'Inh_6', 'Inh_7', 'Inh_8', 'Inh_9', 'Inh_10', 'Inh_11', 'Inh_12', 'Inh_13', 'Inh_14',\n",
    "       'Inh_15', 'Inh_16', 'Inh_17', 'Inh_18', 'Inh_19','Inh_20', 'Inh_21', 'Inh_22', 'Inh_23']\n",
    "\n",
    "roi=pd.read_csv('/Volumes/multifish/Yuhan/LHA_analysis/anatomy/20201007_roi_rigid_transformed_meta_v9_in_microns.csv',sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lha_neuron=pd.read_csv('directory/spotcount/neuron',sep=',', index_col=0)\n",
    "ex_m=pd.read_csv('/Slc17a6/molecular/type/metadata',sep=',', index_col=0)\n",
    "inh_m=pd.read_csv('/Slc32a1/molecular/type/metadata',sep=',', index_col=0)\n",
    "lha_neuron=lha_neuron.T\n",
    "lha_neuron=lha_neuron.where(lha_neuron>=0, 0)\n",
    "roi=pd.read_csv('directory/roi/metadata',sep=',', index_col=0)\n",
    "\n",
    "cluster=pd.concat([ex_m,inh_m],axis=0)\n",
    "\n",
    "c=['Ex-1', 'Ex-2', 'Ex-3', 'Ex-4',\n",
    "   'Ex-5', 'Ex-6', 'Ex-7', 'Ex-8', \n",
    "   'Ex-9', 'Ex-10', 'Ex-11', 'Ex-12', \n",
    "   'Ex-13', 'Ex-14', 'Ex-15', 'Ex-16', \n",
    "   'Ex-17', 'Ex-18', 'Ex-19', 'Ex-20',\n",
    "   'Ex-21', 'Ex-22', 'Ex-23', 'Ex-24', \n",
    "   'Ex-25','Inh-1', 'Inh-2','Inh-3', 'Inh-4', \n",
    "   'Inh-5', 'Inh-6', 'Inh-7', 'Inh-8', 'Inh-9', \n",
    "   'Inh-10', 'Inh-11', 'Inh-12', 'Inh-13', 'Inh-14',\n",
    "   'Inh-15', 'Inh-16', 'Inh-17', 'Inh-18', 'Inh-19',\n",
    "   'Inh-20', 'Inh-21', 'Inh-22', 'Inh-23']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FISH_z=stats.zscore(lha_neuron)\n",
    "fish=pd.DataFrame(data=FISH_z, index=lha_neuron.index, columns=lha_neuron.columns)\n",
    "FISH_log=np.log(lha_neuron+1)\n",
    "fish_log=pd.DataFrame(data=FISH_log, index=lha_neuron.index, columns=lha_neuron.columns)\n",
    "\n",
    "log_z=stats.zscore(FISH_log)\n",
    "log_z=pd.DataFrame(data=log_z, index=lha_neuron.index, columns=lha_neuron.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Split data into training data and test data by random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##predict x, y, z position with gene expression data + other features\n",
    "roi_con=roi.copy()\n",
    "roi_con=roi_con[(roi_con.x<777)&(roi_con.y<772)&(roi_con.z<266)]\n",
    "roi_con=roi_con[roi_con.index.str.contains('LHA5')]\n",
    "n=5000\n",
    "idx=np.random.choice(roi_con.index,n)\n",
    "X_train=log_z[log_z.index.isin(idx)]\n",
    "Y_train=roi_con[roi_con.index.isin(idx)].to_numpy()[:, :3]\n",
    "idx_t=np.random.choice(roi_con[~roi_con.index.isin(idx)].index, n)\n",
    "X_test=log_z[log_z.index.isin(idx_t)]\n",
    "Y_test=roi_con[roi_con.index.isin(idx_t)].to_numpy()[:, :3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Multi-Output Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest regression prediction score:  0.5960931938539519\n"
     ]
    }
   ],
   "source": [
    "max_depth = 30\n",
    "regr_multirf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=max_depth, random_state=0, oob_score=True))\n",
    "regr_multirf.fit(X_train, Y_train)\n",
    "print('Random Forest regression prediction score: ', regr_multirf.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance (ShuffleSplit)  0.60 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "seed = 7\n",
    "SS = model_selection.ShuffleSplit(n_splits=10)\n",
    "\n",
    "scoring = 'explained_variance'\n",
    "regr_multirf.fit(X_train, Y_train)\n",
    "results = model_selection.cross_val_score(regr_multirf, X_test, Y_test,cv=SS, scoring=scoring)\n",
    "print(f\"explained variance (ShuffleSplit)  \"\n",
    "              f\"{results.mean():.2f}\"\n",
    "              f\" +/- {results.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance (10-fold)  0.58 +/- 0.03\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "seed = 7\n",
    "SS = model_selection.KFold(10)\n",
    "\n",
    "scoring = 'explained_variance'\n",
    "regr_multirf.fit(X_train, Y_train)\n",
    "results = model_selection.cross_val_score(regr_multirf, X_test, Y_test,cv=SS, scoring=scoring)\n",
    "print(f\"explained variance (10-fold)  \"\n",
    "              f\"{results.mean():.2f}\"\n",
    "              f\" +/- {results.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance (-Otp/Meis2)  0.57 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "# a=pd.DataFrame(np.empty([len(X_train.columns),0]), index=X_train.columns)\n",
    "# for x in X_train.columns:\n",
    "X1=X_train.drop(columns=['Otp','Meis2'])\n",
    "X2=X_test.drop(columns=['Otp','Meis2'])\n",
    "regr_multirf.fit(X1, Y_train)\n",
    "SS = model_selection.ShuffleSplit(n_splits=10)\n",
    "scoring = 'explained_variance'\n",
    "results = model_selection.cross_val_score(regr_multirf, X2, Y_test,cv=SS, scoring=scoring)\n",
    "print(f\"explained variance (-Otp/Meis2)  \"\n",
    "              f\"{results.mean():.2f}\"\n",
    "              f\" +/- {results.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance(-Slc17a6/Slc32a1)   0.56 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "X1=X_train.drop(columns=['Slc17a6','Slc32a1'])\n",
    "X2=X_test.drop(columns=['Slc17a6','Slc32a1'])\n",
    "regr_multirf.fit(X1, Y_train)\n",
    "SS = model_selection.ShuffleSplit(n_splits=10)\n",
    "scoring = 'explained_variance'\n",
    "results = model_selection.cross_val_score(regr_multirf, X2, Y_test,cv=SS, scoring=scoring)\n",
    "print(f\"explained variance(-Slc17a6/Slc32a1)   \"\n",
    "              f\"{results.mean():.2f}\"\n",
    "              f\" +/- {results.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explained variance(-Otp/Meis2/Slc17a6/Slc32a1)  0.54 +/- 0.02\n"
     ]
    }
   ],
   "source": [
    "# a=pd.DataFrame(np.empty([len(X_train.columns),0]), index=X_train.columns)\n",
    "# for x in X_train.columns:\n",
    "X1=X_train.drop(columns=['Slc17a6','Slc32a1','Otp','Meis2'])\n",
    "X2=X_test.drop(columns=['Slc17a6','Slc32a1','Otp','Meis2'])\n",
    "regr_multirf.fit(X1, Y_train)\n",
    "SS = model_selection.ShuffleSplit(n_splits=10)\n",
    "scoring = 'explained_variance'\n",
    "results = model_selection.cross_val_score(regr_multirf, X2, Y_test,cv=SS, scoring=scoring)\n",
    "print(f\"explained variance(-Otp/Meis2/Slc17a6/Slc32a1)  \"\n",
    "              f\"{results.mean():.2f}\"\n",
    "              f\" +/- {results.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle=[]\n",
    "for i in range(0,1001):\n",
    "    roi\n",
    "    idx=np.random.choice(roi_con.index,n)\n",
    "    X_train=log_z[log_z.index.isin(idx)]\n",
    "    Y_train=roi_con[roi_con.index.isin(idx)].sample(frac = 1).to_numpy()[:, :3]\n",
    "    idx_t=np.random.choice(roi_con[~roi_con.index.isin(idx)].index, n)\n",
    "    X_test=log_z[log_z.index.isin(idx_t)]\n",
    "    Y_test=roi_con[roi_con.index.isin(idx_t)].sample(frac = 1).to_numpy()[:, :3]\n",
    "    regr_multirf.fit(X_train, Y_train)\n",
    "    shuffle=np.append(shuffle, regr_multirf.score(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0003640707039280766"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "clf = DummyRegressor(strategy='mean')\n",
    "clf.fit(X_train, Y_train)\n",
    "DummyRegressor(strategy='mean')\n",
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.DataFrame(np.empty([len(X_train.columns),0]), index=X_train.columns)\n",
    "for x in X_train.columns:\n",
    "    X1=X_train.drop(columns=x)\n",
    "    X2=X_test.drop(columns=x)\n",
    "    regr_multirf.fit(X1, Y_train)\n",
    "    results = model_selection.cross_val_score(regr_multirf, X2, Y_test, cv=SS, scoring=scoring)\n",
    "    a.loc[x,'explained_variance']=results.mean()\n",
    "    a.loc[x,'std']=results.std()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = a['R^2 score'].argsort()[::-1] \n",
    "\n",
    "y_ticks = np.arange(0, len(a.index))\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(y_ticks, a['R^2 score'][sorted_idx])\n",
    "ax.set_yticklabels(a.index[sorted_idx])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_title(\"Random Forest R^2 score (leave out selected feature)\")\n",
    "plt.xlim(0.4, 0.6)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data=np.empty([len(X_train.columns),0]), index=X_train.columns)\n",
    "df['feature_z']=regr_multirf.estimators_[0].feature_importances_\n",
    "df['feature_y']=regr_multirf.estimators_[1].feature_importances_\n",
    "df['feature_x']=regr_multirf.estimators_[2].feature_importances_\n",
    "#df.sort_values(['feature_z', 'feature_y', 'feature_x'], ascending=False)\n",
    "\n",
    "# sorted_idx = df['feature_z'].argsort()\n",
    "# y_ticks = np.arange(0, len(feature_names))\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.barh(y_ticks, df['feature_z'][sorted_idx])\n",
    "# ax.set_yticklabels(feature_names[sorted_idx])\n",
    "# ax.set_yticks(y_ticks)\n",
    "# ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(regr_multirf, X_test, Y_test,n_repeats=30,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_x = permutation_importance(regr_multirf.estimators_[2], X_test, Y_test[:,2],n_repeats=30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_y = permutation_importance(regr_multirf.estimators_[1], X_test, Y_test[:,1],n_repeats=30,random_state=0)\n",
    "r_z = permutation_importance(regr_multirf.estimators_[0], X_test, Y_test[:,0],n_repeats=30,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature_permu_z']=r_z['importances_mean']\n",
    "df['feature_permu_y']=r_y['importances_mean']\n",
    "df['feature_permu_x']=r_x['importances_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = df.feature_mean.argsort()\n",
    "\n",
    "y_ticks = np.arange(0, len(df.index))\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(y_ticks, df.feature_mean[sorted_idx])\n",
    "ax.set_yticklabels(df.index[sorted_idx])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = r.importances_mean.argsort()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(r.importances[sorted_idx].T,\n",
    "           vert=False, labels=X_test.columns[sorted_idx])\n",
    "ax.set_title(\"Feature Importance\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
